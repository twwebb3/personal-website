<!-- notes/templates/notes/data_science.html -->

{% extends "base.html" %}
{% load static %}

{% block extra_css %}
<link rel="stylesheet" href="{% static 'notes/css/notes_detail.css' %}">
{% endblock extra_css %}



{% block content %}

<div class="sub-header">
    <h1>Data Science</h1>
    <h3>
        <a href="{% url 'notes' %}" class="back-link">‚Üê Back to Notes</a>
    </h3>
</div>


<div class="detail-container">
    <aside class="toc">
        <h2>Table of Contents</h2>
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li>
                <a href="#response-modeling">Response Modeling</a>
                <ul>
                    <li><a href="#response-overall">Overall Approach</a></li>
                    <li>
                        <a href="#response-detail">Detailed Approach</a>
                        <ul>
                            <li><a href="#response-detail-preprocessing">Preprocessing</a></li>
                            <li><a href="#response-detail-modeling">Modeling</a></li>
                            <li><a href="#response-detail-testing">Testing</a></li>
                            <li><a href="#response-detail-deployment">Deployment</a></li>
                            <li><a href="#response-detail-monitoring">Monitoring and Refreshing</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <a href="#a-b-testing">A/B Testing</a>
            </li>
            <li>
                <a href="#nlp">Natural Language Processing</a>
                <ul>
                    <li><a href="#sentiment-analysis">Sentiment Analysis</a></li>
                    <li><a href="#text-classification">Text Classification</a></li>
                </ul>
            </li>
            <li><a href="#conclusion">Conclusion</a></li>
        </ul>
    </aside>

    <main class="main-content">
        <section id="introduction">
            <h1>Introduction</h1>
            <p>Welcome to my Data Science notes section. Here you'll find notes on how I approach and think about data science.</p>
        </section>

        <section id="response-modeling">
            <h1>Response Modeling</h1>
            <p>
                Response, or binary classification, modeling is often the solution to picking the lowest hanging fruit
                when solving business problems with machine learning models. The target is a simple binary outcome: did
                an event occur or did it not? This event can be anything from a customer making a purchase to responding
                to a marketing offer. The goal is to predict the probability of the event occuring based on available
                data. The probability score can then be used to improve targeting and optimize resources. Target those
                that are more likely to desire being targeted, and do not bother those that are not.
            </p>

            <section id="response-overall">
                <h2>Overall Approach</h2>
                <p>
                    Here I'll provide a high-level overview of the approach I take when building response models. We'll
                    assume we have the data we need in a SQL table/view or CSV, and it is roughly ready to start
                    building models on.
                </p>
                <ol>
                    <li>Prepocessing</li>
                    <ol>
                        <li>Convert the target to 1 and 0 values, 1 for the desired outcome.</li>
                        <li>
                            Split the data into train, test, and validation sets. For more detail see <a href="#response-detail-preprocessing">here</a>.
                        </li>
                        <li>Handle missing values: impute or drop them.</li>
                        <li>Convert categorical fields to binary/dummy variables.</li>
                        <li>Scale continuous variables in the training set, and use the same scaling factors on test and validation sets.</li>
                    </ol>

                    <li>Modeling</li>
                    <ol>
                        <li>
                            Feature Selection: this is an iterative process. Use domain knowledge and start with a core
                            group of features, and expand from there based on performance.
                        </li>
                        <li>
                            Logistic Regression: a simple model that is easy to interpret and can be used as a baseline.
                            If the data are fairly balanced and the relationship between the features and the target is
                            linear, this model can be a good choice. It is also a good choice when the goal is to
                            understand the relationship between the features and the target. It is not a good choice when
                            the relationship is non-linear.
                        </li>
                        <li>
                            Random Forest: after trying logistic regression, try a random forest model. Do not do any
                            hyperparameter tuning yet. Evaluate and note the performance on the test set.
                        </li>
                        <li>
                            Gradient Boosting: after trying random forest, try a gradient boosting model. Do not do any
                            hyperparameter tuning yet. Evaluate and note the performance on the test set. There are
                            many options: XGBoost, LightGBM, CatBoost, etc. Try them all and see which one performs best.
                        </li>
                        <li>
                            Now that you tried multiple models, pick the one with the best metrics on the test set. For
                            me, this has usually been XGBoost. Whichever it is, proceed with hyperparameter tuning. We'll
                            go into more detail on this in the <a href="#response-detail-modeling">modeling detailed approach</a>
                            section, but the broad approach is to tune hyperparameters to the point of overfitting (when
                            the model performs better on the training set than the test set), and then dial back a bit.
                        </li>
                        <li>
                            Once you arrive at a good metrics on the test set, evaluate the model on the validation set.
                            If the model performs well on the validation set move on to the next step. If not, start over.
                        </li>
                    </ol>

                    <li>Testing</li>
                    <p>
                        The hardest part of testing is getting stakeholder buy-in. Often once you present validation
                        results and the metrics mentioned above, stakeholders will be all in and want to deploy the
                        model on every customer. Fair enough, this is how medicine works, but the fundamentally
                        difference is we are operating in an ever-changing ecosystem. What might have worked on the data
                        you have today may not work going forward, and so we have to prove it works, and continue to
                        prove that it works. This is where testing comes in. In an ideal scenario, we will:
                    </p>
                    <ol>
                        <li>
                            Identify your key metrics: what outcome are you trying to increase/improve?
                        </li>
                        <li>
                            Split your data randomly on future targets:
                            <ul>
                                <li>Control group: receives status quo treatment.</li>
                                <li>Test group: receives treatment based on the model.</li>
                            </ul>
                        </li>
                        <li>
                            Run the test for a predetermined amount of time, and then evaluate the results. Details on
                            evaluation can be found in the <a href="#response-detail-testing">testing detailed approach</a>
                            section.
                        </li>
                    </ol>
                </ol>
            </section>

            <section id="response-detail">
                <h2>Detailed Approach</h2>
                <p>
                    Here we'll go into more detail on the steps outlined in the <a href="#response-overall">overall approach</a>.
                </p>
                <section id="response-detail-preprocessing">
                    <h3>Preprocessing</h3>
                    <p>
                        Getting the data prepared to train models.
                    </p>

                    <h4>The Target</h4>
                    <p>
                        Step one is to identify your target. This is an event that either did or did not occur. You will
                        want a value of 1 for did occur and a value of 0 for did not occur. Then you will want data
                        associated with this event, but only data on things known before the event occurred. Any data
                        for things that occurred after this event are useless. Things known before the event will be
                        used as features to predict the outcome.
                    </p>

                    <h4>Categorical Features</h4>
                    <p>
                        Categorical features will need to be converted to numerical values. This process has a few names:
                        converting to binaries (statistics), converting to dummy variables (econometrics), and one-hot
                        encoding (data science). The process is simple, just take fields that have categorical values
                        and create new fields that are 1 or 0 for each category. An example is say region of residence,
                        this could have values of 'North', 'South', 'East', and 'West'. So you simply create four new
                        columns, say 'north_bin' which is 1 for when the original column has a value of 'North' and 0
                        otherwise, and so on and so forth for the other three values. Pandas has a function for this
                        called pd.get_dummies(). This is easiest done pre splitting your data, and there are not problems
                        with info leaking across your data splits.
                    </p>

                    <h4>Splitting</h4>
                    <p>
                        Split your data into three sets: train, test, and validate. This can be done in two ways:
                        <ol>
                            <li>Randomly, into sizes of train=60%, test=20%, and validation=20%</li>
                            <li>
                                Based on time: train on everything previous to two years ago, test on the subsequent
                                complete year, and validate on the final complete year.
                            </li>
                        </ol>
                    </p>

                    <h4>Scaling</h4>
                    <p>
                        The final step is to scale continuous features. Features like 'months since last purchase' can
                        can range from 0 to however many months of data you have (say 120), or things like 'total spend'
                        can go into the thousands or even more depending upon what you're looking at. These need to be
                        scaled so that fields with higher values do not end up with more importance in predicting the
                        outcome than fields with lower values. There are a few ways to do this:
                    </p>
                </section>
                <section id="response-detail-modeling">
                    <h3>Modeling</h3>
                    <p>
                        Here we will cover training a model on prepared data. This is an iterative process. My process
                        involves throwing a few things at the wall to see what sticks, and then iterating on what sticks.
                    </p>

                    <h4>Logistic Regression</h4>
                    <p>
                        With a fairly balanced target (as in each outcome occurs near 50% of the time) and a good set of
                        features logistic regression can end up being the final model. However, when that is not the
                        case, it is still useful as a first pass to give you a gauge of how good the features you have
                        selected are.
                    </p>

                    <h4>Random Forest</h4>
                    <p>
                        I'll skip decision trees, I've never used them for prediction, just for finding relationships in
                        data that I do not yet fully understand. A Random Forest is a group of decision trees, that are
                        fit simultaneously on the training set using different combinations of the features you specify,
                        and ensembled together to get a final prediction. They work well with both binary and multi-class
                        targets.
                    </p>

                    <h4>Gradient Boosting</h4>
                    <p>
                        There are a few different modules/methods of gradient boosting. I mainly use XGBoost, but it is
                        worth trying CatBoost and LightGBM as well. The process is similar to Random Forest in that
                        many trees are fit or regressions run to ensemble into a final prediction, but these are done
                        sequentially instead of simultaneously. This means that the next tree is fit on the residuals
                        of the previous tree/regression.
                    </p>
                </section>
                <section id="response-detail-testing">
                    <h3>Testing</h3>
                    <p>Data testing is the process of validating and verifying data to ensure data quality, accuracy, and reliability. It involves checking data for consistency, completeness, correctness, and compliance with business rules and requirements.</p>
                </section>
                <section id="response-detail-deployment">
                    <h3>Deployment</h3>
                    <p>Data deployment is the process of implementing data models and solutions into production environments. It involves deploying models, algorithms, and data pipelines to make them accessible to end-users and applications.</p>
                </section>
                <section id="response-detail-monitoring">
                    <h3>Monitoring and Refreshing</h3>
                    <p>Data monitoring is the process of tracking and analyzing data to ensure its quality, integrity, and security. It involves monitoring data pipelines, models, and applications to detect issues, anomalies, and deviations from expected behavior.</p>
                </section>
            </section>
        </section>

        <section id="a-b-testing">
            <h1>A/B Testing</h1>
            <p>
                There are a variety of uses for testing. The end goal is to prove a solution works, the solution could be
                a model, a new marketing offer or message, etc. regardless the process is the same. First you split the
                target audience randomly into control and test groups. The control group receives the status quo treatment,
                and the test group receives the new treatment. After a predetermined amount of time you evaluate the results.
                The predetermined amount of time is calculated best on the expected amount of time it takes to get enough
                data to be able to evaluate the results with some level of statistical confidence.
            </p>
        </section>

        <section id="nlp">
            <h1>Natural Language Processing</h1>
            <p>
                Natural Language Processing (NLP) is simply analyzing raw text data to extract useful information from
                it. Most of my NLP work has been in working with survey and message forum comments. The sections below
                will cover what is most relevant for those use cases. Namely, sentiment analysis and classification.
            </p>

            <section id="sentiment-analysis">
                <h2>Sentiment Analysis</h2>
                <p>
                    Sentiment analysis is the process of analyzing text data to determine the sentiment expressed in it.
                    Is it positive, negative, or neutral? This is useful for understanding customer feedback, and
                    provides a further sense of how customers feel about a product or service. We will cover a few
                    methods, progressing from basic to advanced solutions.
                </p>
            </section>

            <section id="text-classification">
                <h2>Text Classification</h2>
                <p>
                    Many of the methods mentioned below are obsolete now that we have cheap LLMs and basically free
                    local LLM options like local llama. However, this is how it worked up until 2022-3. The end goal of
                    text classification is to classify text into categories or topics. In the case of comments this is
                    useful for quantifying what topics customers are users are talking about, and then showing their
                    general sentiment on different topics.
                </p>
            </section>
        </section>


        <section id="conclusion">
            <h1>Conclusion</h1>
            <p>In conclusion, data science is a multifaceted field that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract meaningful insights from data. Continuous learning and adaptation are key to staying effective in this ever-evolving domain.</p>
        </section>

        <a href="{% url 'notes' %}" class="back-link">‚Üê Back to Notes</a>
    </main>
</div>
{% endblock content %}
